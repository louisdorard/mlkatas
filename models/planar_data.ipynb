{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a self-correcting activity generated by [nbgrader](https://nbgrader.readthedocs.io). Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Run subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify planar data\n",
    "\n",
    "In this activity, you'll search for the best hyperparameters for a Decision Tree classifier on a planar dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML packages\n",
    "import sklearn\n",
    "\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilify functions\n",
    "\n",
    "\n",
    "def plot_planar_data(X, y):\n",
    "    \"\"\"Plot some 2D data\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X[y == 0, 0], X[y == 0, 1], \"or\", alpha=0.5, label=0)\n",
    "    plt.plot(X[y == 1, 0], X[y == 1, 1], \"ob\", alpha=0.5, label=1)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def plot_decision_boundary(pred_func, X, y, figure=None):\n",
    "    \"\"\"Plot a decision boundary\"\"\"\n",
    "\n",
    "    if figure is None:  # If no figure is given, create a new one\n",
    "        plt.figure()\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright)\n",
    "\n",
    "\n",
    "def export_decision_tree(tree):\n",
    "    \"\"\"Export a DT to graphviz format\"\"\"\n",
    "\n",
    "    # If using Jupyter locally, install graphviz with this command: conda install python-graphviz\n",
    "    dot_data = export_graphviz(\n",
    "        tree, out_file=None, filled=True, rounded=True, special_characters=True,\n",
    "    )\n",
    "    return dot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dac18dda7123edde8c6d71e2848842db",
     "grade": false,
     "grade_id": "cell-3006fa3f1350c90e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate moon-shaped, noisy data\n",
    "x, y = make_moons(n_samples=1000, noise=0.4)\n",
    "\n",
    "plot_planar_data(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuestionÂ¶\n",
    "\n",
    "Split data and labels into the `x_train`, `x_test`, `y_train` and `y_test` variables using a 25% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96c1debe4262adcd757b4b9d5858c3a9",
     "grade": false,
     "grade_id": "cell-ddaa4233cfda35cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "801f1f234ec148b5782e5a4d5a4a0baf",
     "grade": true,
     "grade_id": "cell-832215c5196f7f4c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(f'x_train: {x_train.shape}. y_train: {y_train.shape}')\n",
    "print(f'x_test: {x_test.shape}. y_test: {y_test.shape}')\n",
    "\n",
    "assert x_train.shape == (750, 2)\n",
    "assert y_train.shape == (750,)\n",
    "assert x_test.shape == (250, 2)\n",
    "assert y_test.shape == (250,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Create a `DecisionTreeClassifier` instance and store it into the `dt_model` variable. Fit this model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0a72c664ead8ac638e1f3337357b9ce",
     "grade": false,
     "grade_id": "cell-6f2a6cef93415c85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88769acb02a783ac9b216e78125835d0",
     "grade": true,
     "grade_id": "cell-dc94a13ecad281a6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute accuracy on training and test sets\n",
    "train_acc = dt_model.score(x_train, y_train)\n",
    "test_acc = dt_model.score(x_test, y_test)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc * 100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "assert train_acc > 0.95\n",
    "assert test_acc > 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the DT\n",
    "dot_data = export_decision_tree(dt_model)\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "plot_decision_boundary(lambda x: dt_model.predict(x), x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tuning the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Search for the best values of `max_leaf_nodes` and `min_samples_split` through a `GridSearchCV` instance, stored in the `grid_search_cv` variable.\n",
    "\n",
    "The final test accuracy should be above 84%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "658b6125f79e45a1e044564534f86318",
     "grade": false,
     "grade_id": "cell-375a6bb1083de705",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fe0ec3b9502fc9e501d51f6b62c382f",
     "grade": true,
     "grade_id": "cell-eb38cb5d8bac64c8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Search for the best parameters with the specified classifier on training data\n",
    "grid_search_cv.fit(x_train, y_train)\n",
    "\n",
    "# Print the best combination of hyperparameters found\n",
    "print(grid_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bb34fea62ae2978cfee5f6cb1f6fb3f",
     "grade": true,
     "grade_id": "cell-25dd378795f665f4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute accuracy on training and test sets\n",
    "train_acc = grid_search_cv.score(x_train, y_train)\n",
    "test_acc = grid_search_cv.score(x_test, y_test)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc * 100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "assert train_acc > 0.84\n",
    "assert test_acc > 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best classifier\n",
    "dot_data = export_decision_tree(grid_search_cv.best_estimator_)\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "plot_decision_boundary(lambda x: grid_search_cv.predict(x), x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Try other metrics for grid search (f1, ROC AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
